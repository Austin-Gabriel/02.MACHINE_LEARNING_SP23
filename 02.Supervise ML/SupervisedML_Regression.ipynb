{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230b5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os #Interacts with the operating system, e.g. paths, mkdir\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # Allows ploting in a 3D graph\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012b1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:/Users/crist/Documents/02.MSU_MsDataScience/2024.SPRING/04.CSIT598_03SP24_MACHINE-LEARNING/02.MACHINE_LEARNING_SP23/PowerPlantsintheU_Export_TableToExcel.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d64b2a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Install_MW</th>\n",
       "      <th>Total_MW</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>PimSource_encoded</th>\n",
       "      <th>Sector_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-89.685000</td>\n",
       "      <td>45.178600</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-87.758600</td>\n",
       "      <td>45.113600</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-88.008600</td>\n",
       "      <td>44.540000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-88.067800</td>\n",
       "      <td>45.233300</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-89.730600</td>\n",
       "      <td>45.441100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-82.375953</td>\n",
       "      <td>35.380139</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12004</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-79.367698</td>\n",
       "      <td>36.009321</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-79.736312</td>\n",
       "      <td>35.273434</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.910480</td>\n",
       "      <td>42.876570</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-77.275900</td>\n",
       "      <td>41.838000</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12008 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Install_MW  Total_MW  Longitude   Latitude  PimSource_encoded  \\\n",
       "0             2.3       2.3 -89.685000  45.178600                  4   \n",
       "1             1.3       1.3 -87.758600  45.113600                  4   \n",
       "2            91.0      79.0 -88.008600  44.540000                  5   \n",
       "3             3.8       3.8 -88.067800  45.233300                  4   \n",
       "4             2.6       2.6 -89.730600  45.441100                  4   \n",
       "...           ...       ...        ...        ...                ...   \n",
       "12003         3.0       3.0 -82.375953  35.380139                 10   \n",
       "12004         3.0       3.0 -79.367698  36.009321                 10   \n",
       "12005         5.0       5.0 -79.736312  35.273434                 10   \n",
       "12006         1.4       1.4 -73.910480  42.876570                 10   \n",
       "12007         1.1       1.1 -77.275900  41.838000                 10   \n",
       "\n",
       "       Sector_encoded  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   2  \n",
       "3                   2  \n",
       "4                   2  \n",
       "...               ...  \n",
       "12003               4  \n",
       "12004               4  \n",
       "12005               4  \n",
       "12006               4  \n",
       "12007               4  \n",
       "\n",
       "[12008 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns to analyze\n",
    "Scolumns = ['sector_nam','PrimSource','Install_MW','Total_MW','Longitude','Latitude']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data_encoded = df[Scolumns].copy()\n",
    "\n",
    "data_encoded['Sector_encoded'] = label_encoder.fit_transform(df[Scolumns].sector_nam)\n",
    "data_encoded['PimSource_encoded'] = label_encoder.fit_transform(df[Scolumns].PrimSource)\n",
    "\n",
    "\n",
    "# # One-hot encoding\n",
    "# data_encoded = pd.get_dummies(df[Scolumns], columns = ['PrimSource'], dtype='int')\n",
    "\n",
    "data_encoded = data_encoded[['Install_MW','Total_MW','Longitude','Latitude','PimSource_encoded','Sector_encoded']]\n",
    "data_encoded       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af02cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (12008, 5)\n",
      "Shape of target variable (y): (12008,)\n"
     ]
    }
   ],
   "source": [
    "X = data_encoded.drop('Total_MW',axis=1)\n",
    "y = data_encoded['Total_MW']\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of target variable (y):\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1561fd2",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c7540c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your training data and transform the features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "501dbc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.93741830e-04, 7.70696422e-01, 5.10479777e-01, 3.63636364e-01,\n",
       "        3.33333333e-01],\n",
       "       [1.46870915e-04, 7.88796092e-01, 5.09261291e-01, 3.63636364e-01,\n",
       "        3.33333333e-01],\n",
       "       [1.33211920e-02, 7.86447194e-01, 4.98508620e-01, 4.54545455e-01,\n",
       "        3.33333333e-01],\n",
       "       ...,\n",
       "       [6.90293301e-04, 8.64170244e-01, 3.24798132e-01, 9.09090909e-01,\n",
       "        6.66666667e-01],\n",
       "       [1.61558007e-04, 9.18907390e-01, 4.67326061e-01, 9.09090909e-01,\n",
       "        6.66666667e-01],\n",
       "       [1.17496732e-04, 8.87287273e-01, 4.47857091e-01, 9.09090909e-01,\n",
       "        6.66666667e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede81d69",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "224bcdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2289.9702309885315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "decision_tree = DecisionTreeRegressor(\n",
    "    max_depth=6, # increasing could result in overfitting\n",
    "    min_samples_split=120, #increasing can prevent overfitting\n",
    "    min_samples_leaf=8, # increasing can prevent overfitting\n",
    "    max_features='sqrt'\n",
    ",random_state=45)\n",
    "\n",
    "# Train the model\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_dt)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3880cbd",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01c6291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install_MW: 0.9998410723676208\n",
      "PimSource_encoded: 6.69192503592767e-05\n",
      "Latitude: 5.339367428873815e-05\n",
      "Longitude: 2.9033663786210874e-05\n",
      "Sector_encoded: 9.581043944963772e-06\n"
     ]
    }
   ],
   "source": [
    "# Access feature importance\n",
    "feature_importance = decision_tree.feature_importances_\n",
    "\n",
    "# Sort feature importance in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Print feature importance\n",
    "for i in sorted_indices:\n",
    "    print(f\"{X.columns[i]}: {feature_importance[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2e1d1",
   "metadata": {},
   "source": [
    "#### Visualize the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f840675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))  # Adjust the figure size as needed\n",
    "plot_tree(decision_tree, filled=True, feature_names=X.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd6e30",
   "metadata": {},
   "source": [
    "## Cross-Validation Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21cf2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [1100.316623646961, 9637.627024354704, 630.081162572856, 5550.426869012911, 1267.7000291545187]\n",
      "Average MSE: 3637.2303417483904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5  # You can adjust the number of splits as needed\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize an empty list to store MSE scores for each fold\n",
    "mse_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "    decision_tree.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions on the validation fold\n",
    "    y_pred_fold = decision_tree.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate MSE for this fold and append it to the list\n",
    "    mse_fold = mean_squared_error(y_val_fold, y_pred_fold)\n",
    "    mse_scores.append(mse_fold)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "average_mse = np.mean(mse_scores)\n",
    "\n",
    "# Optionally, you can print or display the MSE scores for each fold\n",
    "print(\"MSE scores for each fold:\", mse_scores)\n",
    "print(\"Average MSE:\", average_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e454ef8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd06a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 713.9466894793256\n",
      "Feature 0: Importance = 0.9934594392909663\n",
      "Feature 1: Importance = 0.0019755610979831167\n",
      "Feature 2: Importance = 0.00321242725600475\n",
      "Feature 3: Importance = 0.0011263409110796813\n",
      "Feature 4: Importance = 0.00022623144396616423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Access feature importance\n",
    "feature_importance = random_forest.feature_importances_\n",
    "\n",
    "# Interpret feature importance\n",
    "for i, importance in enumerate(feature_importance):\n",
    "    print(f\"Feature {i}: Importance = {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b473a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 713.9466894793256\n",
      "Mean Absolute Error (MAE): 6.703841211027851\n",
      "R-squared: 0.9916474672765212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "748fb5bf",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE): The MSE measures the average squared difference between the predicted values and the true values. A lower MSE indicates better performance. In your case, the MSE of 713.95 indicates that, on average, the squared difference between the predicted and true values is relatively small.\n",
    "\n",
    "Mean Absolute Error (MAE): The MAE measures the average absolute difference between the predicted values and the true values. Like MSE, a lower MAE indicates better performance. Your MAE of 6.70 suggests that, on average, the absolute difference between the predicted and true values is quite small.\n",
    "\n",
    "R-squared (R2): R-squared is a measure of how well the predictions of the model explain the variability of the true values. It ranges from 0 to 1, with 1 indicating a perfect fit. Your R-squared value of 0.992 suggests that your model explains approximately 99.2% of the variance in the target variable, which is very high and indicates a strong predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefede8",
   "metadata": {},
   "source": [
    "### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f659530b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Get feature names from the dataset\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_indices)), feature_importances[sorted_indices], align='center')\n",
    "plt.yticks(range(len(sorted_indices)), feature_names[sorted_indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50fd99c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdpbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdpbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pdp, get_dataset, info_plots\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create partial dependence plots\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pdp_goals \u001b[38;5;241m=\u001b[39m pdp\u001b[38;5;241m.\u001b[39mpdp_isolate(model\u001b[38;5;241m=\u001b[39mrandom_forest, dataset\u001b[38;5;241m=\u001b[39mX_train, model_features\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns, feature\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdpbox'"
     ]
    }
   ],
   "source": [
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Create partial dependence plots\n",
    "pdp_goals = pdp.pdp_isolate(model=random_forest, dataset=X_train, model_features=X_train.columns, feature=['Feature1', 'Feature2'])\n",
    "pdp.pdp_plot(pdp_goals, 'Feature1 & Feature2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab5195",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc508e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(rf, X_test, y_test)\n",
    "sorted_indices = np.argsort(perm_importance.importances_mean)[::-1]\n",
    "\n",
    "# Plot permutation importance\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(range(len(sorted_indices)), perm_importance.importances_mean[sorted_indices], align='center')\n",
    "plt.yticks(range(len(sorted_indices)), X.columns[sorted_indices])\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Permutation Importance Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc14b3",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "python.exe -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fb492e0",
   "metadata": {},
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# Select features for partial dependence plot\n",
    "features = [0, 1]  # Example features\n",
    "\n",
    "# Plot partial dependence\n",
    "plot_partial_dependence(rf, X_train, features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5631244",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e4627a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3681.213105245629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (K) as needed\n",
    "\n",
    "# Train the model\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2f61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e24eab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 18880.64736405939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming you have your features in X and target variable in y\n",
    "\n",
    "# Initialize the SVM regressor\n",
    "svm_regressor = SVR(kernel='poly')  # You can specify different kernels like 'linear', 'poly', 'sigmoid', etc.\n",
    "\n",
    "# Train the model\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72880a",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert features and target variable to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes\n",
    "print(\"Shape of features (X_tensor):\", X_tensor.shape)\n",
    "print(\"Shape of target variable (y_tensor):\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_tensor and y_tensor are your torch tensors\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = Model(input_size, num_classes)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = accuracy_score(y_test.numpy(), predicted.numpy())\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_tensor and y_tensor are your torch tensors\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = Model(input_size, num_classes)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = accuracy_score(y_test.numpy(), predicted.numpy())\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cfcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
